{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Datasets\n",
    "def load_amazon_reviews():\n",
    "    return pd.read_csv('../data/amazon_com-product_reviews_sample.csv')\n",
    "\n",
    "def load_content_based():\n",
    "    return pd.read_csv('../data/content_based_recommendation_dataset.csv')\n",
    "\n",
    "def load_reviews_ratings():\n",
    "    return pd.read_csv('../data/review_and_ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean Data\n",
    "def clean_text(text):\n",
    "    # Remove special characters and lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
    "    return text.lower().strip()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(str(text)).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Process Amazon Reviews\n",
    "def process_amazon_reviews(df):\n",
    "    # Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Clean text columns using .loc\n",
    "    df.loc[:, 'clean_description'] = df['Product Description'].apply(clean_text)\n",
    "    df.loc[:, 'clean_review'] = df['Review Content'].apply(clean_text)\n",
    "    \n",
    "    # Add sentiment scores\n",
    "    df.loc[:, 'sentiment_score'] = df['Review Content'].apply(get_sentiment)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Process Content Based Dataset\n",
    "def process_content_based(df):\n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Print columns for debugging\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Get numerical columns dynamically\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    print(\"Numerical columns identified:\", numerical_cols)\n",
    "    \n",
    "    if numerical_cols:\n",
    "        # Normalize numerical columns safely using .loc\n",
    "        for col in numerical_cols:\n",
    "            if df[col].max() != df[col].min():\n",
    "                df.loc[:, col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Uniq Id                50 non-null     object \n",
      " 1   Crawl Timestamp        50 non-null     object \n",
      " 2   Billing Uniq Id        50 non-null     object \n",
      " 3   Rating                 0 non-null      float64\n",
      " 4   Review Title           50 non-null     object \n",
      " 5   Review Rating          50 non-null     float64\n",
      " 6   Review Date            50 non-null     object \n",
      " 7   User Id                50 non-null     object \n",
      " 8   Brand                  50 non-null     object \n",
      " 9   Category               49 non-null     object \n",
      " 10  Sub Category           49 non-null     object \n",
      " 11  Product Description    49 non-null     object \n",
      " 12  Asin                   50 non-null     object \n",
      " 13  Url                    50 non-null     object \n",
      " 14  Review Content         50 non-null     object \n",
      " 15  Verified Purchase      50 non-null     object \n",
      " 16  Helpful Review Count   50 non-null     object \n",
      " 17  Manufacturer Response  0 non-null      float64\n",
      " 18  clean_description      50 non-null     object \n",
      " 19  clean_review           50 non-null     object \n",
      " 20  sentiment_score        50 non-null     float64\n",
      "dtypes: float64(4), object(17)\n",
      "memory usage: 8.3+ KB\n",
      "None\n",
      "\n",
      "Sample of Category and Sub Category:\n",
      "                 Category   Sub Category\n",
      "0  Beauty & Personal Care  Personal Care\n",
      "1  Beauty & Personal Care  Personal Care\n",
      "2  Beauty & Personal Care  Personal Care\n",
      "3  Beauty & Personal Care  Personal Care\n",
      "4  Beauty & Personal Care  Personal Care\n",
      "\n",
      "Final Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   name          50 non-null     object \n",
      " 1   description   50 non-null     object \n",
      " 2   preferences   50 non-null     object \n",
      " 3   price         50 non-null     float64\n",
      " 4   relationship  50 non-null     object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "\n",
      "Sample of Final Dataset:\n",
      "                                           name  \\\n",
      "0  Schmidt's Deodorant - Beauty & Personal Care   \n",
      "1  Schmidt's Deodorant - Beauty & Personal Care   \n",
      "\n",
      "                                         description  \\\n",
      "0  schmidts natural deodorant formulas use innova...   \n",
      "1  schmidts natural deodorant formulas use innova...   \n",
      "\n",
      "                                         preferences     price relationship  \n",
      "0  [beauty & personal care, personal care, positi...  0.011100      general  \n",
      "1  [beauty & personal care, personal care, positi...  0.021191      general  \n",
      "\n",
      "Data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# 5. Merge Datasets\n",
    "def create_final_dataset(amazon_df, content_df, reviews_df):\n",
    "    # Create a copy of the DataFrame\n",
    "    amazon_df = amazon_df.copy()\n",
    "    \n",
    "    # Print column info to debug\n",
    "    print(\"Amazon DataFrame Info:\")\n",
    "    print(amazon_df.info())\n",
    "    print(\"\\nSample of Category and Sub Category:\")\n",
    "    print(amazon_df[['Category', 'Sub Category']].head())\n",
    "    \n",
    "    # Create final dataframe\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Safe string conversion function\n",
    "    def safe_lower(x):\n",
    "        if pd.isna(x):\n",
    "            return 'unknown'\n",
    "        return str(x).lower()\n",
    "    \n",
    "    # Process Amazon data\n",
    "    final_df['name'] = amazon_df['Brand'].fillna('Unknown Brand') + ' - ' + amazon_df['Category'].fillna('Unknown Category')\n",
    "    final_df['description'] = amazon_df['clean_description'].fillna('')\n",
    "    \n",
    "    # Create preferences from categories and sentiment\n",
    "    final_df['preferences'] = amazon_df.apply(\n",
    "        lambda row: [\n",
    "            safe_lower(row['Category']),\n",
    "            safe_lower(row['Sub Category']),\n",
    "            'positive' if row.get('sentiment_score', 0) > 0 else 'negative',\n",
    "            'highly_rated' if row.get('Rating', 0) >= 4 else 'low_rated'\n",
    "        ], axis=1\n",
    "    )\n",
    "    \n",
    "    # Add price information from content_based dataset\n",
    "    if len(content_df) > 0 and 'Price of the product' in content_df.columns:\n",
    "        price_col = 'Price of the product'\n",
    "    elif len(content_df) > 0 and 'price' in content_df.columns:\n",
    "        price_col = 'price'\n",
    "    else:\n",
    "        price_col = None\n",
    "    \n",
    "    if price_col:\n",
    "        final_df['price'] = content_df[price_col].values[:len(final_df)]\n",
    "    else:\n",
    "        final_df['price'] = 0\n",
    "    \n",
    "    # Add relationship based on category\n",
    "    category_mapping = {\n",
    "        'electronics': 'tech_enthusiast',\n",
    "        'clothing': 'fashion_lover',\n",
    "        'books': 'reader',\n",
    "        'home & kitchen': 'homemaker'\n",
    "    }\n",
    "    \n",
    "    final_df['relationship'] = amazon_df['Category'].apply(\n",
    "        lambda x: category_mapping.get(safe_lower(x), 'general')\n",
    "    )\n",
    "    \n",
    "    return final_df[['name', 'description', 'preferences', 'price', 'relationship']]\n",
    "\n",
    "# Try creating and saving the final dataset with error handling\n",
    "try:\n",
    "    final_dataset = create_final_dataset(processed_amazon, processed_content, reviews_df)\n",
    "    print(\"\\nFinal Dataset Info:\")\n",
    "    print(final_dataset.info())\n",
    "    print(\"\\nSample of Final Dataset:\")\n",
    "    print(final_dataset.head(2))\n",
    "    \n",
    "    # Save the dataset\n",
    "    save_processed_data(final_dataset, 'processed_data.csv')\n",
    "    print(\"\\nData successfully saved!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during dataset creation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save Processed Data\n",
    "def save_processed_data(df, filename):\n",
    "    df.to_csv(f'../data/processed/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "amazon_df = load_amazon_reviews()\n",
    "content_df = load_content_based()\n",
    "reviews_df = load_reviews_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['Number of clicks on similar products', 'Number of similar products purchased so far', 'Average rating given to similar products', 'Gender', 'Median purchasing price (in rupees)', 'Rating of the product', 'Brand of the product', 'Customer review sentiment score (overall)', 'Price of the product', 'Holiday', 'Season', 'Geographical locations', 'Probability for the product to be recommended to the person']\n",
      "Numerical columns identified: ['Number of clicks on similar products', 'Number of similar products purchased so far', 'Average rating given to similar products', 'Median purchasing price (in rupees)', 'Rating of the product', 'Customer review sentiment score (overall)', 'Price of the product', 'Probability for the product to be recommended to the person']\n",
      "Processing completed successfully!\n",
      "\n",
      "Processed Amazon Reviews shape: (50, 21)\n",
      "Processed Content-based shape: (1474, 13)\n"
     ]
    }
   ],
   "source": [
    "# Process each dataset\n",
    "try:\n",
    "    processed_amazon = process_amazon_reviews(amazon_df)\n",
    "    processed_content = process_content_based(content_df)\n",
    "    print(\"Processing completed successfully!\")\n",
    "    \n",
    "    # Print some information about the processed datasets\n",
    "    print(\"\\nProcessed Amazon Reviews shape:\", processed_amazon.shape)\n",
    "    print(\"Processed Content-based shape:\", processed_content.shape)\n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine our processed datasets\n",
    "print(\"\\nAmazon Reviews Dataset:\")\n",
    "print(\"----------------------\")\n",
    "print(\"Columns:\", processed_amazon.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(processed_amazon.head(2))\n",
    "\n",
    "print(\"\\nContent-based Dataset:\")\n",
    "print(\"----------------------\")\n",
    "print(\"Columns:\", processed_content.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(processed_content.head(2))\n",
    "\n",
    "# Basic statistics of numerical columns\n",
    "print(\"\\nNumerical Statistics for Content-based Dataset:\")\n",
    "print(\"--------------------------------------------\")\n",
    "numerical_cols = processed_content.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(processed_content[numerical_cols].describe())\n",
    "\n",
    "# Check for any missing values\n",
    "print(\"\\nMissing Values Check:\")\n",
    "print(\"-------------------\")\n",
    "print(\"Amazon Reviews Dataset:\\n\", processed_amazon.isnull().sum())\n",
    "print(\"\\nContent-based Dataset:\\n\", processed_content.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Uniq Id                50 non-null     object \n",
      " 1   Crawl Timestamp        50 non-null     object \n",
      " 2   Billing Uniq Id        50 non-null     object \n",
      " 3   Rating                 0 non-null      float64\n",
      " 4   Review Title           50 non-null     object \n",
      " 5   Review Rating          50 non-null     float64\n",
      " 6   Review Date            50 non-null     object \n",
      " 7   User Id                50 non-null     object \n",
      " 8   Brand                  50 non-null     object \n",
      " 9   Category               49 non-null     object \n",
      " 10  Sub Category           49 non-null     object \n",
      " 11  Product Description    49 non-null     object \n",
      " 12  Asin                   50 non-null     object \n",
      " 13  Url                    50 non-null     object \n",
      " 14  Review Content         50 non-null     object \n",
      " 15  Verified Purchase      50 non-null     object \n",
      " 16  Helpful Review Count   50 non-null     object \n",
      " 17  Manufacturer Response  0 non-null      float64\n",
      " 18  clean_description      50 non-null     object \n",
      " 19  clean_review           50 non-null     object \n",
      " 20  sentiment_score        50 non-null     float64\n",
      "dtypes: float64(4), object(17)\n",
      "memory usage: 8.3+ KB\n",
      "None\n",
      "\n",
      "Sample of Category and Sub Category:\n",
      "                 Category   Sub Category\n",
      "0  Beauty & Personal Care  Personal Care\n",
      "1  Beauty & Personal Care  Personal Care\n",
      "2  Beauty & Personal Care  Personal Care\n",
      "3  Beauty & Personal Care  Personal Care\n",
      "4  Beauty & Personal Care  Personal Care\n"
     ]
    }
   ],
   "source": [
    "# Create and save final dataset\n",
    "final_dataset = create_final_dataset(processed_amazon, processed_content, reviews_df)\n",
    "save_processed_data(final_dataset, 'processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete! Check the data/processed/ directory for output files.\n"
     ]
    }
   ],
   "source": [
    "# Also save intermediate processed datasets\n",
    "save_processed_data(processed_amazon, 'processed_amazon.csv')\n",
    "save_processed_data(processed_content, 'processed_content.csv')\n",
    "\n",
    "print(\"Data processing complete! Check the data/processed/ directory for output files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
